---
title: "Data cleaning"
author: "Peiyuan Li"
date: "December 8, 2020"
output: html_document
editor_options: 
  chunk_output_type: console
---
**let us import libraries to clean the data**
```{r, message = FALSE, warning = FALSE}
library(mice)
library(VIM)
```

**Let us read the dataset using read.csv command**
```{r, message = FALSE, warning = FALSE}
WHO_data <- read.csv("Life Expectancy Data.csv",header=TRUE)
```

## **Data description**
**Let us check how the data is structured**
```{r, message = FALSE, warning = FALSE}
str(WHO_data)
```
As we can see, there are 22 variables and almost 3000 entries. Moreover, we can see that there are three data types: Factor, int, and num. It defines the nature of each variable, whether the variable is defined by a number or a factor.\

**Let us check the percentage missing values in the dataset**
```{r, message = FALSE, warning = FALSE}
missing_percent <- function(x){sum(is.na(x))/length(x)*100}
apply(WHO_data, 2, missing_percent)
```
There are at most, about 22 percent of missing values in one variable. It would not be wise to delete the entire row for that missing value. Sicne this method results at least 22 percent of data loss, which is an amount we cannot afford.\

**introducing one new additional data point** \
One new additional point is introduced based on the original data variables. This data point in created based on an imaginary realistic Utopian state, where the expected quality of life is very high. I intended to test out the life expectancy in a utopian state.\
Country: Utopia.\
Year: 2020 \
Status: Developed.\
Life expectancy: very high \ 
Adult mortality: 50 \
Alcohol: 12 \ 
BMI: 40 \
Death under five: 0 \
Polio vaccine rate: 99 \
Total expenditure rate: 10 \
Diphtheria vaccine rate: 99 \
HIV rate: 0.1 \
GDP per capita: 80000 \
Income composition of resources: 0.9 \

## **Missing value imputation**
**We may impute the missing value with functions in "mice" package**
```{r, message = FALSE, warning = FALSE}
impute1 <- mice(WHO_data[,1:7], m = 3, seed = 999)
```
This function allows R to impute missing values based on the second column to the seventh column. we can specify 3 imputations, with a random seed '999'.\
```{r}
print(impute1)
```
Since all of the missing values are numeric, it suggests imputation methods called "Predictive Mean Matching".\

**Let us check some imputed values**
```{r}
head(impute1$imp$Alcohol)
```
For example, we can check all the rows that has missing values for variable "Alchol". And there are 3 imputations generated.\
```{r}
WHO_data[33, 1:7] #missing value for variable "Alchol"
WHO_data[34, 1:7]
WHO_data[49, 1:7] #missing value for variable "Alchol"
WHO_data[50, 1:7]
```
It appears that Predictive Mean Matching method is doing very well for the missing variables.\
```{r}
complete(impute1, 1)[c(33, 49, 65, 81),]
```
Finally, we use "complete" function to create a complete dataset, which the missing values been replaced with imputed values.\

**we can use the aboved method to fill all missing values**
```{r message=FALSE, warning=FALSE, include=FALSE}
impute4 <- mice(WHO_data[,c(1:17, 19:22)], m = 3, seed = 999)
WHO_data_filled <- complete(impute4, 1)
```

```{r eval=FALSE}
impute4 <- mice(WHO_data[,c(1:17, 19:22)], m = 3, seed = 999)
WHO_data_filled <- complete(impute4, 1)
```
I used Predictive Mean Matching method for all variables except for variable population. Since variable population has more than 22% missing values, and population distribution across the world vary considerably. It would be unreasonable to predict population based on other variables given in the dataset. Therefore, I dropped variable population.\

## **Data type checking**
**Let us check if the data type is making sense**
```{r}
str(WHO_data_filled)
WHO_data_filled$Year <- as.factor(WHO_data_filled$Year)
```
One more thing we need to make sure is that we should convert varibale year as a categorical data, function "as.factor" is what we needed.\
At this point, We can confirm that there is no missing values. Furthermore, all values are making sense. We may proceed to data exploration.
